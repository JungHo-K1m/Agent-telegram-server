import os, asyncio
import openai
import re
import time
import random
from typing import List, Dict
from utils.logging import get_logger

logger = get_logger(__name__)

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (1.0+ ë²„ì „)
client = openai.AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

ROLE_GUIDE = {
    "Chatter":   "You are a friendly content sharer. Respond naturally like a real person.",
    "Moderator": "You are a strict but polite moderator.",
    "Admin":     "You are the system administrator bot.",
}

# ì—°ì† ë©”ì‹œì§€ ì¶”ì ì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜
message_buffer = {}  # {chat_id: {"messages": [], "last_time": timestamp}}

def is_incomplete_sentence(text: str) -> bool:
    """ë¬¸ì¥ì´ ì™„ì„±ë˜ì§€ ì•Šì•˜ëŠ”ì§€ íŒë‹¨"""
    
    # 1. ë¬¸ì¥ ë¶€í˜¸ë¡œ ëë‚˜ëŠ”ì§€ í™•ì¸
    has_ending = text.strip().endswith(('.', '!', '?', '~', 'ã…‹', 'ã…'))
    
    # 2. ì¡°ì‚¬ë‚˜ ë¶ˆì™„ì „í•œ ë‹¨ì–´ë¡œ ëë‚˜ëŠ”ì§€ í™•ì¸
    incomplete_endings = [
        'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ°ë°', 'ê·¸ë˜ì„œ', 'ê·¸ëŸ¬ë©´',
        'ì€', 'ëŠ”', 'ë„', 'ë§Œ', 'ë¶€í„°', 'ê¹Œì§€', 'ì—ì„œ', 'ì—ê²Œ',
        'ì•ˆë…•', 'ì˜¤ëŠ˜', 'ë‚´ì¼', 'ì–´ì œ', 'ì§€ê¸ˆ', 'ë‚˜ì¤‘ì—',
        'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ°ë°', 'ê·¸ë˜ì„œ', 'ê·¸ëŸ¬ë©´'
    ]
    
    ends_with_incomplete = any(text.endswith(word) for word in incomplete_endings)
    
    # 3. ìˆ«ìë‚˜ íŠ¹ìˆ˜ë¬¸ìë¡œ ëë‚˜ëŠ” ê²½ìš°
    ends_with_number = text[-1].isdigit() if text else False
    ends_with_symbol = text[-1] in '+-*/=()[]{}' if text else False
    
    # 4. í•œ ê¸€ìë¡œ ëë‚˜ëŠ” ê²½ìš°
    is_single_char = len(text.strip()) == 1
    
    result = not has_ending or ends_with_incomplete or ends_with_number or ends_with_symbol or is_single_char
    
    logger.debug("ğŸ” ë¬¸ì¥ ì™„ì„±ë„ íŒë‹¨", 
                text=text, 
                has_ending=has_ending,
                ends_with_incomplete=ends_with_incomplete,
                ends_with_number=ends_with_number,
                ends_with_symbol=ends_with_symbol,
                is_single_char=is_single_char,
                is_incomplete=result)
    
    return result

def should_wait_for_more_messages(chat_id: str, current_message: str, context: list[dict] = None) -> bool:
    """ë” ë§ì€ ë©”ì‹œì§€ë¥¼ ê¸°ë‹¤ë ¤ì•¼ í•˜ëŠ”ì§€ íŒë‹¨"""
    
    global message_buffer
    
    # 1. í˜„ì¬ ì‹œê°„
    current_time = time.time()
    
    # 2. ì±„íŒ…ë°©ë³„ ë©”ì‹œì§€ ë²„í¼ ì´ˆê¸°í™”
    if chat_id not in message_buffer:
        message_buffer[chat_id] = {
            "messages": [],
            "last_time": current_time
        }
    
    buffer = message_buffer[chat_id]
    
    # 3. ì‹œê°„ì´ ë„ˆë¬´ ì˜¤ë˜ ì§€ë‚¬ìœ¼ë©´ ë²„í¼ ì´ˆê¸°í™” (30ì´ˆ)
    if current_time - buffer["last_time"] > 30:
        buffer["messages"] = []
        logger.debug("ğŸ”„ ë²„í¼ ì´ˆê¸°í™” (30ì´ˆ ê²½ê³¼)", chat_id=chat_id)
    
    # 4. í˜„ì¬ ë©”ì‹œì§€ë¥¼ ë²„í¼ì— ì¶”ê°€
    buffer["messages"].append(current_message)
    buffer["last_time"] = current_time
    
    logger.debug("ğŸ“ ë©”ì‹œì§€ ë²„í¼ì— ì¶”ê°€", 
                chat_id=chat_id, 
                message=current_message,
                buffer_count=len(buffer["messages"]))
    
    # 5. ì—°ì† ë©”ì‹œì§€ì¸ì§€ íŒë‹¨
    if len(buffer["messages"]) == 1:
        # ì²« ë²ˆì§¸ ë©”ì‹œì§€ì¸ ê²½ìš°
        is_incomplete = is_incomplete_sentence(current_message)
        logger.debug("ğŸ” ì²« ë²ˆì§¸ ë©”ì‹œì§€ íŒë‹¨", 
                    chat_id=chat_id, 
                    message=current_message,
                    is_incomplete=is_incomplete)
        return is_incomplete
    
    # 6. ì—¬ëŸ¬ ë©”ì‹œì§€ê°€ ìˆëŠ” ê²½ìš°
    combined_message = " ".join(buffer["messages"])
    
    # 7. ì™„ì„±ëœ ë¬¸ì¥ì¸ì§€ í™•ì¸
    if not is_incomplete_sentence(combined_message):
        # ì™„ì„±ëœ ë¬¸ì¥ì´ë©´ ë²„í¼ ì´ˆê¸°í™”
        buffer["messages"] = []
        logger.debug("âœ… ì™„ì„±ëœ ë¬¸ì¥ ê°ì§€", 
                    chat_id=chat_id, 
                    combined_message=combined_message)
        return False
    
    # 8. ì•„ì§ ì™„ì„±ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ë” ê¸°ë‹¤ë¦¼
    logger.debug("â³ ì•„ì§ ì™„ì„±ë˜ì§€ ì•Šì€ ë¬¸ì¥", 
                chat_id=chat_id, 
                combined_message=combined_message,
                buffer_count=len(buffer["messages"]))
    return True

def get_combined_message(chat_id: str) -> str:
    """ë²„í¼ì˜ ëª¨ë“  ë©”ì‹œì§€ë¥¼ í•©ì³ì„œ ë°˜í™˜"""
    global message_buffer
    
    if chat_id in message_buffer:
        combined = " ".join(message_buffer[chat_id]["messages"])
        message_buffer[chat_id]["messages"] = []  # ë²„í¼ ì´ˆê¸°í™”
        logger.debug("ğŸ”— ë²„í¼ ë©”ì‹œì§€ ê²°í•©", 
                    chat_id=chat_id, 
                    combined_message=combined)
        return combined
    
    logger.debug("ğŸ“­ ë²„í¼ê°€ ë¹„ì–´ìˆìŒ", chat_id=chat_id)
    return ""

async def should_respond_to_message(message: str, context: list[dict] = None, chat_id: str = None) -> bool:
    """ë©”ì‹œì§€ì— ë‹µë³€í•´ì•¼ í• ì§€ íŒë‹¨"""
    
    logger.info("ğŸ” ë©”ì‹œì§€ í•„í„°ë§ ì‹œì‘", 
                message=message, 
                chat_id=chat_id,
                context_length=len(context) if context else 0)
    
    # 1. ì—°ì† ë©”ì‹œì§€ ì²˜ë¦¬
    if chat_id and should_wait_for_more_messages(chat_id, message, context):
        logger.info("â³ ì—°ì† ë©”ì‹œì§€ ëŒ€ê¸° ì¤‘", 
                    chat_id=chat_id, 
                    message=message)
        return False  # ë” ê¸°ë‹¤ë¦¼
    
    # ì‹¤ì œ ì²˜ë¦¬í•  ë©”ì‹œì§€ (ì—°ì† ë©”ì‹œì§€ê°€ í•©ì³ì§„ ê²ƒ)
    actual_message = get_combined_message(chat_id) if chat_id else message
    
    if actual_message != message:
        logger.info("ğŸ”— ì—°ì† ë©”ì‹œì§€ ê²°í•©", 
                    original=message, 
                    combined=actual_message)
    
    # 2. ëª…ë°±í•œ ë¬´ì˜ë¯¸í•œ ë©”ì‹œì§€ í•„í„°ë§
    meaningless_patterns = [
        r'^[ã…‹ã…]+$',  # ì›ƒìŒë§Œ
        r'^[ã…‡ã…]+$',  # ì¶”ì„ìƒˆë§Œ
        r'^[.]{2,}$',  # ì ë§Œ
        r'^[~]{2,}$',  # ë¬¼ê²°ë§Œ
        r'^[!]{2,}$',  # ëŠë‚Œí‘œë§Œ
        r'^[?]{2,}$',  # ë¬¼ìŒí‘œë§Œ
        r'^[ã…ã…‡ã…]+$',  # ì¶”ì„ìƒˆ ì¡°í•©
        r'^[ã…‹ã…!~.]+$',  # ê°ì • í‘œí˜„ë§Œ
    ]
    
    for pattern in meaningless_patterns:
        if re.match(pattern, actual_message.strip()):
            logger.info("âŒ ë¬´ì˜ë¯¸í•œ íŒ¨í„´ í•„í„°ë§", 
                        pattern=pattern, 
                        message=actual_message)
            return False
    
    # 3. ì§§ì€ ì¶”ì„ìƒˆ í•„í„°ë§
    short_responses = ['ìŒ', 'ì–´', 'ì‘', 'ê·¸ë˜', 'ë§ì•„', 'ì¢‹ì•„', 'ã…‡ã…‡', 'ã…‡', 'ã…', 'ã…‹']
    if actual_message.strip() in short_responses:
        logger.info("âŒ ì§§ì€ ì¶”ì„ìƒˆ í•„í„°ë§", 
                    message=actual_message)
        return False
    
    # 4. AIì—ê²Œ ì§ˆë¬¸í•˜ëŠ”ì§€ íŒë‹¨
    question_keywords = ['?', 'ë­', 'ë¬´ì—‡', 'ì–´ë–»ê²Œ', 'ì™œ', 'ì–¸ì œ', 'ì–´ë””', 'ëˆ„ê°€', 'ëª‡']
    has_question = any(keyword in actual_message for keyword in question_keywords)
    
    if has_question:
        logger.info("âœ… ì§ˆë¬¸ ê°ì§€", 
                    message=actual_message, 
                    keywords=[k for k in question_keywords if k in actual_message])
    
    # 5. ë§¥ë½ ê¸°ë°˜ íŒë‹¨ (AIì—ê²Œ ì§ì ‘ ì–¸ê¸‰)
    direct_mentions = ['ë„ˆ', 'ë‹¹ì‹ ', 'AI', 'ë´‡', 'ê¸°ê³„', 'ë¡œë´‡']
    is_direct_mention = any(mention in actual_message for mention in direct_mentions)
    
    if is_direct_mention:
        logger.info("âœ… ì§ì ‘ ì–¸ê¸‰ ê°ì§€", 
                    message=actual_message, 
                    mentions=[m for m in direct_mentions if m in actual_message])
    
    # 6. ëŒ€í™” ë§¥ë½ ë¶„ì„ (ì„ íƒì‚¬í•­)
    context_analysis = False
    if context and len(context) > 0:
        # ìµœê·¼ ëŒ€í™”ì—ì„œ AIê°€ ì–¸ê¸‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
        recent_context = context[-3:]  # ìµœê·¼ 3ê°œ ë©”ì‹œì§€
        for msg in recent_context:
            if msg.get('role') == 'assistant':
                # AIê°€ ìµœê·¼ì— ì–¸ê¸‰ë˜ì—ˆë‹¤ë©´ ë” ì ê·¹ì ìœ¼ë¡œ ì‘ë‹µ
                context_analysis = True
                logger.info("âœ… ë§¥ë½ ë¶„ì„: AI ìµœê·¼ ì–¸ê¸‰ ê°ì§€")
                break
    
    # 7. ìµœì¢… íŒë‹¨
    # ì§ˆë¬¸ì´ ìˆê±°ë‚˜ ì§ì ‘ ì–¸ê¸‰ì´ ìˆìœ¼ë©´ ì‘ë‹µ
    if has_question or is_direct_mention:
        logger.info("âœ… ì‘ë‹µ ê²°ì •: ì§ˆë¬¸ ë˜ëŠ” ì§ì ‘ ì–¸ê¸‰", 
                    has_question=has_question, 
                    is_direct_mention=is_direct_mention)
        return True
    
    # ê¸´ ë©”ì‹œì§€(10ì ì´ìƒ)ëŠ” ì‘ë‹µ
    if len(actual_message.strip()) >= 10:
        logger.info("âœ… ì‘ë‹µ ê²°ì •: ê¸´ ë©”ì‹œì§€", 
                    length=len(actual_message.strip()), 
                    message=actual_message)
        return True
    
    # ì§§ì€ ë©”ì‹œì§€ëŠ” 30% í™•ë¥ ë¡œë§Œ ì‘ë‹µ (ìì—°ìŠ¤ëŸ¬ì›€)
    should_respond = random.random() < 0.3
    
    logger.info("ğŸ² ì§§ì€ ë©”ì‹œì§€ í™•ë¥  íŒë‹¨", 
                message=actual_message, 
                length=len(actual_message.strip()), 
                probability=0.3, 
                result=should_respond)
    
    if should_respond:
        logger.info("âœ… ì‘ë‹µ ê²°ì •: í™•ë¥  ê¸°ë°˜")
    else:
        logger.info("âŒ ì‘ë‹µ ê±°ë¶€: í™•ë¥  ê¸°ë°˜")
    
    return should_respond

async def generate_reply(persona_prompt: str, role: str, context: list[dict], user_msg: str):
    """ê¸°ë³¸ ì‘ë‹µ ìƒì„±"""
    messages = (
        context
        + [{"role": "system", "content": persona_prompt}]
        + [{"role": "assistant", "content": ROLE_GUIDE[role]}]
        + [{"role": "user", "content": user_msg}]
    )

    resp = await client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.7,
    )
    return resp.choices[0].message.content

async def generate_multi_reply(persona_prompt: str, role: str, context: list[dict], user_msg: str, chat_participants: List[str] = None):
    """ì—¬ëŸ¬ ëª…ì—ê²Œ ë‹µì¥í•˜ëŠ” ì‘ë‹µ ìƒì„±"""
    
    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ë©€í‹° ë¦¬í”Œë¼ì´ ê°€ì´ë“œ ì¶”ê°€
    multi_reply_guide = """
    You are in a group chat. When responding to multiple people or complex situations:
    1. You can respond to multiple people in one message
    2. You can split your response into multiple messages if it's more natural
    3. Use @username to mention specific people when needed
    4. Keep responses conversational and natural
    5. If the conversation involves multiple topics, address them separately
    
    Format your response as:
    - Single response: Just write normally
    - Multiple responses: Use "---SPLIT---" to separate different messages
    Example:
    "Hey @john, that's a great point! ---SPLIT--- @sarah, I think you're right about that too."
    """
    
    enhanced_prompt = persona_prompt + "\n\n" + multi_reply_guide
    
    messages = (
        context
        + [{"role": "system", "content": enhanced_prompt}]
        + [{"role": "assistant", "content": ROLE_GUIDE[role]}]
        + [{"role": "user", "content": user_msg}]
    )

    resp = await client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.7,
    )
    
    response_text = resp.choices[0].message.content
    
    # ì‘ë‹µì„ ì—¬ëŸ¬ ê°œë¡œ ë¶„í• 
    if "---SPLIT---" in response_text:
        return [msg.strip() for msg in response_text.split("---SPLIT---") if msg.strip()]
    else:
        return [response_text]

async def generate_natural_reply(persona_prompt: str, role: str, context: list[dict], user_msg: str):
    """ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µ ìƒì„± (íƒ€ì´í•‘ íš¨ê³¼, ì§€ì—° ë“±)"""
    
    natural_guide = """
    You are a real person in a group chat. Be natural and conversational:
    1. Use casual language and emojis when appropriate
    2. Show personality and emotion
    3. Sometimes use "..." or "hmm" to show thinking
    4. Be responsive to the conversation flow
    5. Don't be too formal or robotic
    """
    
    enhanced_prompt = persona_prompt + "\n\n" + natural_guide
    
    messages = (
        context
        + [{"role": "system", "content": enhanced_prompt}]
        + [{"role": "assistant", "content": ROLE_GUIDE[role]}]
        + [{"role": "user", "content": user_msg}]
    )

    resp = await client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.8,  # ë” ì°½ì˜ì ì¸ ì‘ë‹µ
    )
    
    return resp.choices[0].message.content 